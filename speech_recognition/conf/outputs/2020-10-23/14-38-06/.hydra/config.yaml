type: train
auto_lr: false
batch_size: 128
experiment_id: test
fold_bn: -1
lr: 0.05
seed: 1234
num_workers: 0
output_dir: trained_models
dump_test: false
input_file: ''
dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/speech_commands_v0.02/
  dataset: keywords
  cls: speech_recognition.dataset.SpeechCommandsDataset
  input_length: 16000
  features: mel
  freq_max: 4000
  freq_min: 20
  full_help: false
  group_speakers_by_id: true
  height: 40
  n_mels: 40
  n_mfcc: 40
  normalize_bits: 0
  normalize_max: 256
  unknown_prob: 0.1
  test_pct: 10
  test_snr: .inf
  dev_pct: 10
  timeshift_ms: 100
  train_pct: 80
  train_snr_high: 1000.0
  train_snr_low: 0.0
  wanted_words:
  - 'yes'
  - 'no'
  - up
  - down
  - left
  - right
  - 'on'
  - 'off'
  - stop
  - go
  use_default_split: false
  samplingrate: 16000
  silence_prob: 0.1
  extract_loudest: true
  stride_ms: 10
  window_ms: 30
model:
  model: tc-res8
  model_class: speech_recognition.models.tc.models.TCResNetModel
  model_name: tc-res8
  separable:
  - 0
  - 0
  block1_conv_size: 9
  block1_output_channels: 24
  block1_stride: 2
  block2_conv_size: 9
  block2_output_channels: 32
  block2_stride: 2
  block3_conv_size: 9
  block3_output_channels: 48
  block3_stride: 2
  bottleneck:
  - 0
  - 0
  channel_division:
  - 2
  - 4
  conv1_output_channels: 16
  conv1_size: 3
  conv1_stride: 1
  dropout_prob: 0.5
  fully_convolutional: false
  inputlayer: true
  width_multiplier: 1.0
  dilation: 1
  clipping_value: 100000
  small: false
  width: 101
  height: 40
  n_labels: 12
scheduler:
  _target_: torch.optim.lr_scheduler.StepLR
  step_size: 20
  gamma: 0.1
  last_epoch: -1
optimizer:
  _target_: torch.optim.adam.Adam
  lr: 0.001
  betas:
  - 0.9
  - 0.999
  eps: 1.0e-08
  weight_decay: 0
  amsgrad: false
features:
  _target_: torchaudio.transforms.MFCC
  sample_rate: 16000
  n_mfcc: 40
  dct_type: 2
  norm: ortho
  win_length: null
  hop_length: null
  f_min: 0.0
  f_max: null
  pad: 0
  n_mels: 128
  power: 2.0
  normalized: false
trainer:
  gpus: null
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 80
  default_root_dir: .,
  row_log_interval: 1
  fast_dev_run: false
  overfit_batches: 0.01
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  filepath: ./checkpoints
  save_top_k: 5
  verbose: true
  monitor: val_loss
  mode: min
  prefix: ''
