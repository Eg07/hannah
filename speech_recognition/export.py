import sys
from typing import Any, Text, Iterable, List, Dict, Sequence, Optional, Tuple, Union

from torch.utils.data import DataLoader

import onnx
from onnx import optimizer
from onnx import utils
from onnx import numpy_helper, ValueInfoProto, AttributeProto, GraphProto, NodeProto, TensorProto, TensorShapeProto

import numpy as np

from .config import ConfigBuilder
from . import dataset

def _convertAttributeProto(onnx_arg):  # type: (AttributeProto) -> AttributeValue
    """
    Convert an ONNX AttributeProto into an appropriate Python object
    for the type.
    NB: Tensor attribute gets returned as numpy array
    """
    if onnx_arg.HasField('f'):
        return onnx_arg.f
    elif onnx_arg.HasField('i'):
        return onnx_arg.i
    elif onnx_arg.HasField('s'):
        return onnx_arg.s
    elif onnx_arg.HasField('t'):
        return numpy_helper.to_array(onnx_arg.t)
    elif len(onnx_arg.floats):
        return list(onnx_arg.floats)
    elif len(onnx_arg.ints):
        return list(onnx_arg.ints)
    elif len(onnx_arg.strings):
        return list(onnx_arg.strings)
    else:
        raise ValueError("Unsupported ONNX attribute: {}".format(onnx_arg))


def _input_from_onnx_input(input):  # type: (ValueInfoProto) -> EdgeInfo
    name = input.name
    type = input.type.tensor_type.elem_type
    shape = tuple([d.dim_value for d in input.type.tensor_type.shape.dim])
    return (name, type, shape)

class Attributes(Dict[Text, Any]):
    @staticmethod
    def from_onnx(args):  # type: (Iterable[AttributeProto]) -> Attributes
        d = Attributes()
        for arg in args:
            d[arg.name] = _convertAttributeProto(arg)
        return d

class ComputeNode(object):

    def __init__(self, name, op_type, attrs, inputs, outputs):
        self.name = name
        self.op_type = op_type
        self.attrs = attrs
        self.inputs = inputs
        self.outputs = outputs

        self.input_tensors = {}  # type: Dict[Text, np._ArrayLike[Any]]
        self.parents = []  # type: List[Node]
        self.children = []  # type: List[Node]
        self.metadata = {} # type: Dict[Any, Any]
    
    @staticmethod
    def from_onnx(node):  # type: (NodeProto) -> Node
        attrs = Attributes.from_onnx(node.attribute)
        name = Text(node.name)
        if len(name) == 0:
            name = node.op_type + "_".join(node.output)
        return ComputeNode(name, node.op_type, attrs, list(node.input), list(node.output))
        

class ComputeGraph(object):

    def __init__(self, nodes, inputs, outputs, shape_dict):
        self.nodes = nodes
        self.inputs = inputs
        self.outputs = outputs
        self.shape_dict = shape_dict


        # data blob name to the list of op types it feeds into
        self.blob_to_op_type = {} # type: Dict[Text, List[Text]]
        # data blob name to the op_type that generates it
        self.blob_from_op_type = {}  # type: Dict[Text, Text]

        self.constant_layers_added = {} # type: Dict[Text, bool]

        for node_ in nodes:
            for input_ in node_.inputs:
                if input_ in self.blob_to_op_type:
                    self.blob_to_op_type[input_].append(node_.op_type)
                else:
                    self.blob_to_op_type[input_] = [node_.op_type]
            for output_ in node_.outputs:
                if output_ in self.blob_from_op_type:
                    raise ValueError("Data blob: %s, is generated by more than 1 op" %(output_))
                self.blob_from_op_type[output_] = node_.op_type
        
        
    @staticmethod
    def from_onnx(graph):  # type: (GraphProto) -> Graph
        input_tensors = {
            t.name: numpy_helper.to_array(t) for t in graph.initializer
        }

        
        nodes_ = []
        nodes_by_input = {}  # type: Dict[Text, List[Node]]
        nodes_by_output = {}
        for node in graph.node:
            node_ = ComputeNode.from_onnx(node)
            for input_ in node_.inputs:
                if input_ in input_tensors:
                    node_.input_tensors[input_] = input_tensors[input_]
                else:
                    if input_ in nodes_by_input:
                        input_nodes = nodes_by_input[input_]
                    else:
                        input_nodes = []
                        nodes_by_input[input_] = input_nodes
                    input_nodes.append(node_)
            for output_ in node_.outputs:
                nodes_by_output[output_] = node_
            nodes_.append(node_)

        inputs = []
        for i in graph.input:
            if i.name not in input_tensors:
                inputs.append(_input_from_onnx_input(i))

        outputs = []
        for o in graph.output:
            outputs.append(_input_from_onnx_input(o))

        for node_ in nodes_:
            for input_ in node_.inputs:
                if input_ in nodes_by_output:
                    node_.parents.append(nodes_by_output[input_])
            for output_ in node_.outputs:
                if output_ in nodes_by_input:
                    node_.children.extend(nodes_by_input[output_])

        # Dictionary to hold the "value_info" field from ONNX graph
        shape_dict = {} # type: Dict[Text,Tuple[int,...]]
        def extract_value_info(shape_dict, # type: Dict[Text,Tuple[int,...]]
                               value_info, # type: ValueInfoProto[...]
                               ):
            # type: (...) -> None
            t = tuple([int(dim.dim_value) for dim in value_info.type.tensor_type.shape.dim])
            if t:
                shape_dict[value_info.name] = t

        for value_info in graph.value_info:
            extract_value_info(shape_dict, value_info)

        return ComputeGraph(nodes_, inputs, outputs, shape_dict)


def constant_propagation(graph):

    class OperationState(object):
        def __init__(self, node, state):
            self.node = node
            self.output_state =  [state]
    
    worklist = []
    for node in graph.nodes:
        if node.op_type == "Shape":
            print(node)
            worklist.append(OperationState(node, []))
        elif node.op_type == "Constant":
            print(node)
            worklist.append(OperationState(node, []))

    state_dict = {}
    while worklist:
        node = worklist.pop()

        
    
def export_model(config):
    onnx_model = onnx.load(config["input_file"])
    onnx.checker.check_model(onnx_model)


    ## Set input batch size to 0
    onnx_model.graph.input[0].type.tensor_type.shape.dim[0].dim_value = 1

    ## Remove Dropouts
    for op_id, op in enumerate(onnx_model.graph.node):
        if op.op_type == "Dropout":
            op.attribute[0].f = 0.0

    ##TODO: remove BatchNorm
        
    print("Running model optimization")
    optimized_model = optimizer.optimize(onnx_model, ["eliminate_nop_dropout"])
    optimized_model = utils.polish_model(optimized_model)

    #print(onnx.helper.printable_graph(optimized_model.graph))
    
    onnx.save(optimized_model, "polished_model.onnx")

    graph = ComputeGraph.from_onnx(optimized_model.graph)

    constant_propagation(graph)
    
    # Generate Node Parameters
    parameter_header = "#ifndef NETWORK_PARAMETERS_H\n";
    parameter_header += "#define NETWORK_PARAMETERS_H\n";
    parameter_header += "#include \"pico-cnn/parameters.h\"\n\n"
    parameter_code = "#include \"network_parameters.h\"\n\n";
    for node in graph.nodes:
        print(node.name, node.op_type)
        
        if node.input_tensors:
            if node.op_type == "Conv" or node.op_type == "Gemm":
                print(node.inputs)
                type_code = "fp_t " + node.name + "_" + "coef[]"
                declaration = "extern " + type_code + ";"
                coef = node.input_tensors[node.inputs[1]]
                coef = np.moveaxis(coef, 1, -1)
                definition  = type_code + " = {" + ",".join((str(x) for x in coef.flatten())) + "};"

                parameter_code += definition + "\n"
                parameter_header += declaration + "\n"

                type_code = "fp_t " + node.name + "_" + "bias[]"
                declaration = "extern " + type_code + ";"
                definition  = type_code + " = {" + ", ".join((str(x) for x in node.input_tensors[node.inputs[2]])) + "};"

                parameter_code += definition + "\n\n"
                parameter_header += declaration + "\n\n"
    parameter_header += "#endif \n"
                
    with open("network_parameters.h", "w") as f:
        f.write(parameter_header)

    with open("network_parameters.c", "w") as f:
        f.write(parameter_code)

    network_header = "#ifndef NETWORK_H\n"
    network_header += "#define NETWORK_H\n"
    network_header += "#include \"pico-cnn/parameters.h\"\n\n"
    network_header += "void network(fp_t *input, fp_t *output);\n"
    network_header += "#endif //NETWORK_H\n"

    network_code =  "#include \"network.h\"\n"
    network_code += "#include \"network_parameters.h\"\n\n"
    network_code += "#include \"pico-cnn/pico-cnn.h\"\n"
    network_code += "void network(fp_t *input, fp_t *output\n){"
    for num, node in enumerate(graph.nodes):
        network_code += "//Layer " + str(num) + " " +  node.name + " " +   node.op_type + "\n"
        network_code += "//Attributes\n"
        for key, val in node.attrs.items():
            network_code += "//  " + str(key) + ": " + str(val) + "\n"
        network_code += "//Parameters\n"

        if node.op_type == "Conv":
            print("generating_convolution")

        elif node.op_type == "Gemm":
            print("generating fully connected layer")

        elif node.op_type == "MaxPool":
            print("generating max pooling layer")

        elif node.op_type == "Relu":
            print("generating max pooling layer")

        else:
            print("Unhandled node type:", node.op_type)
        
        network_code += "\n"
        
    network_code += "}\n"

    with open("network.c", "w") as f:
        f.write(network_code)

    with open("network.h", "w") as f:
        f.write(network_header)

        
def export_data(config):
    print("Exporting_input_data")
    train_set, dev_set, test_set = dataset.SpeechDataset.splits(config)
    test_loader = DataLoader(test_set, batch_size=1, shuffle=True)

    data, label = next(iter(test_loader))
    print(data.shape, label)
    data = data.numpy().flatten()
    
    data_code = "#ifndef INPUT_DATA_H\n"
    data_code += "#include \"pico-cnn/parameters.h\"\n\n"
    data_code += "fp_t input[] = {" + ",".join((str(x) for x in data)) + "};\n"
    data_code += "#endif //INPUT_DATA_H\n"
    with open("input_data.h", "w") as f:
        f.write(data_code)
    
def main():
    global_config = dict(seed=0, input_file="", output_dir=".", cache_size=31288)
    builder = ConfigBuilder(
        dataset.SpeechDataset.default_config(),
        global_config)
    parser = builder.build_argparse()
    config = builder.config_from_argparse(parser)

    export_model(config)
    export_data(config)
    
        
if __name__ == "__main__":
    main()
