
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Preprocessing &#8212; Speech Recognition 0.1.0 documentation</title>
    <link rel="stylesheet" href="_static/classic.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/language_data.js"></script>
    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Networks" href="networks.html" />
    <link rel="prev" title="Structure" href="structure.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="networks.html" title="Networks"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="structure.html" title="Structure"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">Speech Recognition 0.1.0 documentation</a> &#187;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="preprocessing">
<h1>Preprocessing<a class="headerlink" href="#preprocessing" title="Permalink to this headline">¶</a></h1>
<div class="section" id="dataset">
<h2>Dataset<a class="headerlink" href="#dataset" title="Permalink to this headline">¶</a></h2>
<p>The dataset enhancement is implemented in module speech_recognition.dataset</p>
<p>The dataset classes perform the following operations:</p>
<ol class="arabic simple">
<li><p>Splitting the WAV-files of a dataset in training, development and test_set</p></li>
<li><p>Reading of WAV-Files and Labels</p></li>
<li><p>Resampling of WAV-Files to desired frequency</p></li>
<li><p>If the dataset provides background noise files, background noise is added to the   audios</p></li>
<li><p>Caching of preprocessed audios</p></li>
<li><p>Running of the feature extraction</p></li>
<li><p>Caching of extracted features</p></li>
<li><p>Provides an interface to the features and associated labels suitable for
training and evaluation</p></li>
</ol>
<p>The dataset preprocessing has the following command line interface:</p>
<blockquote>
<div><table class="docutils align-center">
<colgroup>
<col style="width: 48%" />
<col style="width: 52%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Parameter</p></th>
<th class="head"><p>Default</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>–test-pct TEST_PCT</p></td>
<td><p>10</p></td>
</tr>
<tr class="row-odd"><td><p>–silence-prob SILENCE_PROB</p></td>
<td><p>0.1</p></td>
</tr>
<tr class="row-even"><td><p>–dev-pct DEV_PCT</p></td>
<td><p>10</p></td>
</tr>
<tr class="row-odd"><td><p>–data-folder DATA_FOLDER</p></td>
<td><p>datasets/speech_commands_v0.02/</p></td>
</tr>
<tr class="row-even"><td><p>–noise-prob NOISE_PROB</p></td>
<td><p>0.8</p></td>
</tr>
<tr class="row-odd"><td><p>–no-extract-loudest</p></td>
<td><p>True</p></td>
</tr>
<tr class="row-even"><td><p>–timeshift-ms TIMESHIFT_MS</p></td>
<td><p>100</p></td>
</tr>
<tr class="row-odd"><td><p>–unknown-prob UNKNOWN_PROB</p></td>
<td><p>0.1</p></td>
</tr>
<tr class="row-even"><td><p>–samplingrate SAMPLINGRATE</p></td>
<td><p>16000</p></td>
</tr>
<tr class="row-odd"><td><p>–train-pct TRAIN_PCT</p></td>
<td><p>80</p></td>
</tr>
<tr class="row-even"><td><p>–wanted-words WANTED_WORDS</p></td>
<td><p>see command line</p></td>
</tr>
<tr class="row-odd"><td><p>–use-default-split</p></td>
<td><p>False</p></td>
</tr>
<tr class="row-even"><td><p>–input-length INPUT_LENGTH</p></td>
<td><p>16000</p></td>
</tr>
<tr class="row-odd"><td><p>–loss {cross_entropy,ctc}</p></td>
<td><p>cross_entropy</p></td>
</tr>
<tr class="row-even"><td><p>–no-group-speakers-by-id</p></td>
<td><p>True</p></td>
</tr>
</tbody>
</table>
</div></blockquote>
<span class="target" id="module-speech_recognition.dataset"></span><dl class="class">
<dt id="speech_recognition.dataset.DatasetType">
<em class="property">class </em><code class="descclassname">speech_recognition.dataset.</code><code class="descname">DatasetType</code><a class="reference internal" href="_modules/speech_recognition/dataset.html#DatasetType"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speech_recognition.dataset.DatasetType" title="Permalink to this definition">¶</a></dt>
<dd><p>The type of a dataset partition e.g. train, dev, test</p>
</dd></dl>

<dl class="class">
<dt id="speech_recognition.dataset.SimpleCache">
<em class="property">class </em><code class="descclassname">speech_recognition.dataset.</code><code class="descname">SimpleCache</code><span class="sig-paren">(</span><em>limit</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speech_recognition/dataset.html#SimpleCache"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speech_recognition.dataset.SimpleCache" title="Permalink to this definition">¶</a></dt>
<dd><p>A simple in memory cache used for audio files and preprocessed features</p>
</dd></dl>

<dl class="class">
<dt id="speech_recognition.dataset.SpeechCommandsDataset">
<em class="property">class </em><code class="descclassname">speech_recognition.dataset.</code><code class="descname">SpeechCommandsDataset</code><span class="sig-paren">(</span><em>data</em>, <em>set_type</em>, <em>config</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speech_recognition/dataset.html#SpeechCommandsDataset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speech_recognition.dataset.SpeechCommandsDataset" title="Permalink to this definition">¶</a></dt>
<dd><p>This class implements reading and preprocessing of speech commands like 
dataset</p>
</dd></dl>

<dl class="class">
<dt id="speech_recognition.dataset.SpeechDataset">
<em class="property">class </em><code class="descclassname">speech_recognition.dataset.</code><code class="descname">SpeechDataset</code><span class="sig-paren">(</span><em>data</em>, <em>set_type</em>, <em>config</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speech_recognition/dataset.html#SpeechDataset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speech_recognition.dataset.SpeechDataset" title="Permalink to this definition">¶</a></dt>
<dd><p>Base Class for speech datasets</p>
<dl class="staticmethod">
<dt id="speech_recognition.dataset.SpeechDataset.default_config">
<em class="property">static </em><code class="descname">default_config</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/speech_recognition/dataset.html#SpeechDataset.default_config"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speech_recognition.dataset.SpeechDataset.default_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the default configuration for the Dataset and 
Feature extraction</p>
</dd></dl>

<dl class="method">
<dt id="speech_recognition.dataset.SpeechDataset.preprocess">
<code class="descname">preprocess</code><span class="sig-paren">(</span><em>example</em>, <em>silence=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speech_recognition/dataset.html#SpeechDataset.preprocess"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speech_recognition.dataset.SpeechDataset.preprocess" title="Permalink to this definition">¶</a></dt>
<dd><p>Run preprocessing and feature extraction</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="speech_recognition.dataset.SpeechHotwordDataset">
<em class="property">class </em><code class="descclassname">speech_recognition.dataset.</code><code class="descname">SpeechHotwordDataset</code><span class="sig-paren">(</span><em>data</em>, <em>set_type</em>, <em>config</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speech_recognition/dataset.html#SpeechHotwordDataset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speech_recognition.dataset.SpeechHotwordDataset" title="Permalink to this definition">¶</a></dt>
<dd><p>Dataset Class for Hotword dataset e.g. Hey Snips!</p>
<dl class="staticmethod">
<dt id="speech_recognition.dataset.SpeechHotwordDataset.default_config">
<em class="property">static </em><code class="descname">default_config</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/speech_recognition/dataset.html#SpeechHotwordDataset.default_config"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speech_recognition.dataset.SpeechHotwordDataset.default_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the default configuration for the Dataset and 
Feature extraction</p>
</dd></dl>

<dl class="classmethod">
<dt id="speech_recognition.dataset.SpeechHotwordDataset.splits">
<em class="property">classmethod </em><code class="descname">splits</code><span class="sig-paren">(</span><em>config</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speech_recognition/dataset.html#SpeechHotwordDataset.splits"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speech_recognition.dataset.SpeechHotwordDataset.splits" title="Permalink to this definition">¶</a></dt>
<dd><p>Splits the dataset in training, devlopment and test set and returns
the three sets as List</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="speech_recognition.dataset.ctc_collate_fn">
<code class="descclassname">speech_recognition.dataset.</code><code class="descname">ctc_collate_fn</code><span class="sig-paren">(</span><em>data</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speech_recognition/dataset.html#ctc_collate_fn"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speech_recognition.dataset.ctc_collate_fn" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates mini-batch tensors from the list of tuples (src_seq, trg_seq).
We should build a custom collate_fn rather than using default collate_fn,
because merging sequences (including padding) is not supported in default.
Sequences are padded to the maximum length of mini-batch sequences (dynamic padding).
Args:</p>
<blockquote>
<div><dl class="simple">
<dt>data: list of tuple (src_seq, src_length, trg_seq, trg_length).</dt><dd><ul class="simple">
<li><p>src_seq: torch tensor of shape (x,?); variable length.</p></li>
<li><p>src length: torch tenso of shape 1x1</p></li>
<li><p>trg_seq: torch tensor of shape (?); variable length.</p></li>
<li><p>trg_length: torch_tensor of shape (1x1)</p></li>
</ul>
</dd>
</dl>
</div></blockquote>
<dl class="simple">
<dt>Returns: tuple of four torch tensors</dt><dd><p>src_seqs: torch tensor of shape (batch_size, x, padded_length).
src_lengths: torch_tensor of shape (batch_size); valid length for each padded source sequence.
trg_seqs: torch tensor of shape (batch_size, x, padded_length).
trg_lengths: torch tensor of shape (batch_size); valid length for each padded target sequence.</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="speech_recognition.dataset.find_dataset">
<code class="descclassname">speech_recognition.dataset.</code><code class="descname">find_dataset</code><span class="sig-paren">(</span><em>name</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speech_recognition/dataset.html#find_dataset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speech_recognition.dataset.find_dataset" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the appropriate class for reading a dataset of type name:</p>
<dl>
<dt>name<span class="classifier">str</span></dt><dd><p>The name of the dataset type</p>
<blockquote>
<div><ul class="simple">
<li><p>keywords = Google Speech Commands like  dataset</p></li>
<li><p>hotword = Hey Snips! like dataset</p></li>
</ul>
</div></blockquote>
</dd>
</dl>
<p>Returns</p>
</dd></dl>

</div>
<div class="section" id="feature-extraction">
<h2>Feature Extraction<a class="headerlink" href="#feature-extraction" title="Permalink to this headline">¶</a></h2>
<p>We currently support the following preprocessing directives:</p>
<ol class="arabic simple">
<li><p>Mel Frequency Cepstral Coefficients (MFCC) implemented as implemented in honk (mel)</p></li>
<li><p>Mel Frequency Cepstral Coefficients (MFCC) as implemented in librosa (mfcc)</p></li>
<li><p>Mel Frequency Spectrum e.g. MFCC with (melspec)</p></li>
<li><p>Spectrogram as implemented in librosa (spectrogram)</p></li>
<li><p>RAW-Audio (raw)</p></li>
</ol>
<p>Feature extraction has the following command line interface:</p>
<table class="docutils align-center">
<colgroup>
<col style="width: 83%" />
<col style="width: 17%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Parameter</p></th>
<th class="head"><p>Default</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>–freq-max FREQ_MAX</p></td>
<td><p>4000</p></td>
</tr>
<tr class="row-odd"><td><p>–n-mfcc N_MFCC</p></td>
<td><p>40</p></td>
</tr>
<tr class="row-even"><td><p>–stride-ms STRIDE_MS</p></td>
<td><p>10</p></td>
</tr>
<tr class="row-odd"><td><p>–window-ms WINDOW_MS</p></td>
<td><p>30</p></td>
</tr>
<tr class="row-even"><td><p>–freq-min FREQ_MIN</p></td>
<td><p>20</p></td>
</tr>
<tr class="row-odd"><td><p>–n-mels N_MELS</p></td>
<td><p>40</p></td>
</tr>
<tr class="row-even"><td><p>–features {mel,mfcc,melspec,spectrogram,raw}</p></td>
<td><p>mel</p></td>
</tr>
</tbody>
</table>
<p>Feature extreaction is implemented in the module speech_recognition.preprocess_audio.</p>
<span class="target" id="module-speech_recognition.process_audio"></span><p>This module implements feature extraction from raw audio data</p>
<dl class="function">
<dt id="speech_recognition.process_audio.calculate_feature_shape">
<code class="descclassname">speech_recognition.process_audio.</code><code class="descname">calculate_feature_shape</code><span class="sig-paren">(</span><em>input_length</em>, <em>features='mel'</em>, <em>samplingrate=1600</em>, <em>n_mels=40</em>, <em>n_mfcc=40</em>, <em>stride_ms=10</em>, <em>window_ms=10</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speech_recognition/process_audio.html#calculate_feature_shape"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speech_recognition.process_audio.calculate_feature_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculates the shape of the given features</p>
<blockquote>
<div><dl class="simple">
<dt>input_length<span class="classifier">int</span></dt><dd><p>lenght of the input in samples</p>
</dd>
<dt>features<span class="classifier">str</span></dt><dd><p>The selected feature to extract. Currently one of: 
- raw: for RAW single channel audiodata
- mel: Mel Frequency Cepstral Coefficients
- mfcc: Alternative implementation of Mel Frequency Cepstral Coefficients
- melspec: Mel-scaled spectrogram
- spectrogram: Spectrogram</p>
</dd>
<dt>n_mels: int</dt><dd><p>Number of frequency bands in melspectrogram</p>
</dd>
<dt>n_mfcc: int</dt><dd><p>Number of mfcc/mel features after dct</p>
</dd>
<dt>stride_ms: int</dt><dd><p>Stride of the feature extractor in ms</p>
</dd>
<dt>window_ms: int</dt><dd><p>Size of the feature window in ms</p>
</dd>
</dl>
</div></blockquote>
<dl class="simple">
<dt>Returns: (int, int)</dt><dd><p>Shape of the features (N,T). T is temporal dimension, N is number of channels.</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="speech_recognition.process_audio.preprocess_audio">
<code class="descclassname">speech_recognition.process_audio.</code><code class="descname">preprocess_audio</code><span class="sig-paren">(</span><em>data</em>, <em>features='mel'</em>, <em>samplingrate=1600</em>, <em>n_mels=40</em>, <em>n_mfcc=40</em>, <em>dct_filters=None</em>, <em>freq_min=20</em>, <em>freq_max=4000</em>, <em>window_ms=40</em>, <em>stride_ms=10</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speech_recognition/process_audio.html#preprocess_audio"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speech_recognition.process_audio.preprocess_audio" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculates the features for a given audio</p>
<blockquote>
<div><dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>input_length<span class="classifier">int</span></dt><dd><p>lenght of the input in samples</p>
</dd>
<dt>features<span class="classifier">str</span></dt><dd><p>The selected feature to extract. Currently one of: 
- raw: for RAW single channel audiodata
- mel: Mel Frequency Cepstral Coefficients
- mfcc: Alternative implementation of Mel Frequency Cepstral Coefficients
- melspec: Mel-scaled spectrogram
- spectrogram: Spectrogram</p>
</dd>
<dt>dct_filters: np.ndarray </dt><dd><p>Dct filter coefficients to transform mel scaled spectrograms into 
MFCC features.</p>
</dd>
<dt>n_mels: int</dt><dd><p>Number of frequency bands in melspectrogram</p>
</dd>
<dt>n_mfcc: int</dt><dd><p>Number of mfcc/mel features after dct</p>
</dd>
<dt>stride_ms: int</dt><dd><p>Stride of the feature extractor in ms</p>
</dd>
<dt>window_ms: int</dt><dd><p>Size of the feature window in ms</p>
</dd>
</dl>
</dd>
</dl>
</div></blockquote>
<dl class="simple">
<dt>Returns: np.ndarray (NxT)</dt><dd><p>Extracted features N is channel dimenstion, T is Temporal dimension</p>
</dd>
</dl>
</dd></dl>

</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Preprocessing</a><ul>
<li><a class="reference internal" href="#dataset">Dataset</a></li>
<li><a class="reference internal" href="#feature-extraction">Feature Extraction</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="structure.html"
                        title="previous chapter">Structure</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="networks.html"
                        title="next chapter">Networks</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/preprocessing.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="networks.html" title="Networks"
             >next</a> |</li>
        <li class="right" >
          <a href="structure.html" title="Structure"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">Speech Recognition 0.1.0 documentation</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2019, Christoph Gerum, Adrian Frischknecht.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 2.0.1.
    </div>
  </body>
</html>